---
title: "Water Quality Data Analysis System"
author: "APEM Ltd"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
 rmdformats::downcute:
    highlight: tango
    number_sections: yes
    theme: united
editor_options: 
  chunk_output_type: console
---

<img src="ApemLogo.JPG" style="position:absolute;top:0px;right:0px;"/>


```{r setup, include=FALSE}

############################################### OPERATING INSTRUCTIONS ###############################################
#
## Introduction
#
# This is the Water Quality Data Analysis System, developed by APEM Ltd. This workflow will build a  report for given site IDs and return tables showing potential data issues, summaries of the data split by site, a location map and time series charts for each location/parameter. The charts include interactive metric plots to allow individual data points to be investigated. 
#
## Running the Toolbox:
#
# * Create a copy of this RStudio project and, if not present, transfer a copy of this script to the new folder. This project should also contain a folder called "Data", which contains input data files. 
# * Before running the tool, configure the Settings in the section below, which allow users to specify:
#   * Site IDs, both EA and APEM (maximum six sites per run). The order in which sites are specified will be reflecetd in the plots/tables.
#   * A start date for the macroinvertebrate samples (if required).
#   * An end date for the macroinvertebrate samples (if required).
#   * A path to any APEM data to be imported into the tool
#   * A guideline standard to be applied to the LIFE metric plots (0.94 or 1.0)
#   * A flag to indicate whether or not to apply trend lines to the metric plots.
#   * A flag to indicate whether or not to apply confidence intervals to trend lines in metric plots (if applied).
#   * A filter to select data only for specific seasons
#   * Options to set default values for the environmental parameters required for RICT
# * Save a copy of the script with your parameters specified.  
# * To run the script, use the Knit button above. This will render the report as an HTML document, saved to the top level project folder (see the files tab to the right). By default, the report will be called MI_analysis_vX.html (the report name matches the name of this script file). 
######################################################################################################################

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE)
rm(list = ls())

```

# Settings

```{r settings}

# Specify the name of the file containing APEM data to be imported. 
# Data must be saved in the Data folder, but the folder should not be specified here.
TEMPLATE_PATH <- "WQ template example_data.xlsx"

# Specify the sheets to be imported from the input template. To import all worksheets enter "all"
# Otherwise list individual worksheets in quotes: c("PROBE_DATA", "MANUAL_FIELD", "LAB_DATA").
SHEETS <- c("PROBE_DATA", "MANUAL_FIELD", "LAB_DATA")

# Start date for samples. Leave as NULL to keep all available data. If specifying date use format "YYYY-MM-DD" (including quotes).
START_DATE <- NULL

# End date for samples. Leave as NULL to keep all available data. If specifying date use format "YYYY-MM-DD" (including quotes).
END_DATE <- NULL

# Specify the parameters to be analysed.
# Use "All" (the default) to import all available parameters.
PARAMETERS <- "All"

# Specify all APEM water quality location names to be imported from the template in the form: c("Site1", "site2").
# Use "All" (the default) to import all data from the template.
APEM_SITES <- "All" 

# Specify all EA WIMS site IDs for which data should be downloaded in the form: c("WIMS1", "WIMS2").
# Use "All" (the default) to import data for all sites within the import template with a corresponding WIMS ID.
# If EA data is not required, use NULL
EA_SITES <- "All"

# Specify a multiplier to be used for handing chemistry results outwith the LOD. Must be between 0 and 1.
# The LOD will be multiplied by this value to generate dummy results.
LOD_MULTIPLIER <- 0.5

# Specify a folder to save output files to
OUTPUT_PATH <- "Outputs/"

# Specify style for time series plots. The available options are:
# "line"  = WFD levels are delimited by coloured, dashed lines. Use this option if tributary rivers need to be highlighted
# "block" = WFD levels are delimited by coloured blocks. Tributary rivers cannot be highlighted.
CHART_TYPE <- "line"
# On the charts, identify the source of the data
SHOW_DATA_SOURCE <- FALSE
# On nitrate charts, show old standard at 11.3mg/L
SHOW_NITRATE_STANDARD <- TRUE

```

```{r libraries}

## LIBRARIES

# Load required libraries
if(!require(pacman)) install.packages("pacman")
pacman::p_load(remotes, readxl, dplyr, stringr, lubridate, ggplot2, writexl, 
               tidyr, DT, rnrfa, leaflet, downloader, sf, GGally, gridextra,
               rlang, readr, openxlsx, scales, htmltools, dygraphs, ggh4x, extrafont) # new for WQ tool

# Conditionally install hetoolkit from github
if ("hetoolkit" %in% installed.packages() == FALSE) {
  remotes::install_github("APEM-LTD/hetoolkit")
}

library(hetoolkit)

# Add tool-specific functions
source("R/wq_functions.R")

```

```{r process_user_entry}

# if (is.null(TEMPLATE_PATH) == TRUE) {
#   import_APEM <- ""
#   TEMPLATE_PATH <- "NA - no APEM data supplied"
# } else {
#   import_APEM <- "R/WQ_import_APEM.Rmd"
# }

# Process user date entry for reporting
if(is.null(START_DATE) == TRUE) {
  SDATE <- "NA - using all data"
} else {
  SDATE <- as.character(START_DATE)
}

if(is.null(END_DATE) == TRUE) {
  EDATE <- "NA - using all data"
} else {
  EDATE <- as.character(END_DATE)
}

# Convert chart type to lower case
CHART_TYPE <- stringr::str_to_lower(CHART_TYPE)

```

```{r entry_check, warning=TRUE, error=FALSE}

## Check input file exists
if(is.null(TEMPLATE_PATH == FALSE && exists(TEMPLATE_PATH) == FALSE)){
  stop("Input template file does not exist")
}

## Sheet names exist in template
if(is.null(TEMPLATE_PATH) == FALSE){
  template_sheets <- readxl::excel_sheets(paste0("Data/", TEMPLATE_PATH))
  sheets_exist <- lapply(SHEETS, function(s) s %in% template_sheets)
  if(FALSE %in% sheets_exist == TRUE){
    stop("Specified sheets do not all exist in input template file")
  }
}

## Start date in correct format
if(is.null(START_DATE) == FALSE && IsDate(START_DATE, "%Y-%m-%d") == FALSE) {
  stop("Start date should be in YYYY-MM-DD format")
}

## End date in correct format
if(is.null(END_DATE) == FALSE && IsDate(END_DATE, "%Y-%m-%d") == FALSE) {
  stop("Start date should be in YYYY-MM-DD format")
}

## End date after start date
if((is.null(START_DATE) == FALSE && as.Date(START_DATE) > Sys.Date()) == TRUE) {
  stop("Start data cannot be in the future")
}

## Start date after 2000 (WQA database cut off for EA data)
if((is.null(START_DATE) == FALSE && as.Date(START_DATE) < as.Date("2000-01-01")) == TRUE) {
  print("NOTE: EA data is not availble from the WQA database before year 2000")
}

## Valid parameters specified
if (PARAMETERS != "All"){
  check_names(PARAMETERS, ALLOWED_PARAMS)
} else {
  PARAMETERS <- ALLOWED_PARAMS
}

## LOD multiplier is numeric
if(is.numeric(LOD_MULTIPLIER) == FALSE){
  stop("LOD multiplier must be numeric")
}

## LOD multiplier within valid range
if(LOD_MULTIPLIER < 0 || LOD_MULTIPLIER > 1) {
  stop("LOD multiplier must be between 0 and 1")
}

## Chart type is valid
if (CHART_TYPE %in% c("line", "block") == FALSE) {
  stop("The chart type must be either 'line' or 'block'.")
}

```

User-specified settings:  

 * Import template file: **`r TEMPLATE_PATH`**  
 * Source sheets to import: **`r SHEETS`**  
 * APEM sites to import: **`r APEM_SITES`** 
 * EA Sites to import: **`r EA_SITES`**
 * Start date: **`r SDATE`** 
 * End date: **`r EDATE`** 
 * Parameters of interest: **`r PARAMETERS`**  
 * LOD multiplier: **`r LOD_MULTIPLIER`**
 * Output folder: **`r OUTPUT_PATH`**
 * Chart style: **`r CHART_TYPE`**
 * Show data sources on chart: **`r SHOW_DATA_SOURCE`**
 
```{r import}

# IMPORT FROM TEMPLATE
# Load specified sheets into a list
sheets <- lapply(SHEETS, function(i) readxl::read_excel(paste0("Data/", TEMPLATE_PATH), sheet = i))
names(sheets) <- SHEETS

params <- readxl::read_excel(paste0("Data/", TEMPLATE_PATH),
                             sheet = "PARAMETERS")   # Loads PARAMETERS tab with details of column headers

metadata <- readxl::read_excel(paste0("Data/", TEMPLATE_PATH),
                             sheet = "METADATA") %>%    # Loads PARAMETERS tab with details of column headers)
  dplyr::filter(!(if_any(c(location_name, location_id, wb_type, altitude, main_trib),is.na)))

standards <- readxl::read_excel(paste0("Data/", TEMPLATE_PATH),
                                sheet = "STANDARDS")   # Loads STANDARDS tab with details of WFD boundaries)

desc <- readxl::read_excel(paste0("Data/", TEMPLATE_PATH),
                                sheet = "OUTPUT_SHEETS")   # Loads OUTPUT_SHEETS tab with details of exported data)

## ERROR CHECK for specified parameters
# allowed_params <- params$parameter
# if (PARAMETERS != "All"){
#   check_names(PARAMETERS, allowed_params)
# } else {
#   PARAMETERS <- allowed_params
# }

```

```{r data_checks}

### Metadata
## Check wb type completed
if(sum(is.na(metadata$wb_type)) > 0) {
  stop("Waterbody type (salmonid/cyprinid) must be completed for all sites.")
}

## Check wb type completed
if(sum(is.na(metadata$altitude)) > 0) {
  stop("Site altidude (lowland/upland) must be completed for all sites.")
}

## Check for altitude_m/alkalinity
if(sum(is.na(metadata$altitude_m)) > 0 | sum(is.na(metadata$alkalinity)) > 0) {
  warning("Site altitude and/or alkalinity not specified. Unable to calculate orthophosphate standards")
}



```

```{r ea_import}

## AUTO-IMPORT EA DATA
if(is.null(EA_SITES) == FALSE){
  
  if ("All" %in% EA_SITES) {
    EA_SITES <- unique(metadata$EA_ID)
  } 
  
  # Pull all data for sites
  ea_wq_data <- hetoolkit::import_wq(sites = EA_SITES,
                                     dets = c(61, 76, 85, 111, 117, 180, 9901)) # fixed for specified WFD parameters
  
  # filter by dates
  if(is.null(START_DATE) == FALSE){
    ea_wq_data <- wq_data %>%
      dplyr::filter(date >= START_DATE)
  }
  
  if(is.null(END_DATE) == FALSE){
    ea_wq_data <- wq_data %>%
      dplyr::filter(date <= END_DATE)
  }
  
  ### Identify results outwith LOD
  ea_wq_data<- ea_wq_data  %>%
      dplyr::mutate(result = ifelse(is.na(qualifier) == FALSE, paste0(qualifier, result), result))
  
  ### Update param names to match template
  ea_wq_data <- ea_wq_data %>%
    dplyr::left_join(params, by = c("det_label" = "WIMS_headers")) %>%
    dplyr::select(c(wq_site_id, date, parameter, det_id, result, units, qualifier)) %>%
    dplyr::rename(EA_ID = wq_site_id)
  
  # Get sampling point details (need lat/long in particular)
  ea_site_info <- get_wq_site_info(ea_wq_data, "EA_ID") %>%
    dplyr::select(c(EA_ID, lat, long)) %>%
    dplyr::rename(latitude = lat, longitude = long)
  
  # Restructure
  ea_wq_data <- ea_wq_data %>%
    dplyr::left_join(ea_site_info) %>%
    tidyr::pivot_wider(id_cols = c(EA_ID, latitude, longitude, date),
                       names_from = parameter,
                       values_from = result) %>%
    dplyr::mutate(time = as.POSIXct("1899-12-31 00:01"),
                  source = "EA_DATA") %>%
    dplyr::left_join(metadata) %>%
    dplyr::select(!c(EA_ID, location_id, wb_type, altitude))
  
} else {
  ea_wq_data <- readr::read_csv("Data/wq_data_blank.csv")
}

```

```{r merge}

if ("All" %in% APEM_SITES) {
  APEM_SITES <- unique(metadata$location_name)
} 

# Drop empty sheets or add source variable
for (sheet in SHEETS) {
  if (nrow(sheets[[sheet]]) == 0){
    sheets[[sheet]] <- NULL
  } else {
    sheets[[sheet]] <- sheets[[sheet]] %>%
      dplyr::mutate(source = sheet) %>%
      #dplyr::left_join(metadata) %>%
      dplyr::filter(location_name %in% APEM_SITES)
    for (p in PARAMETERS){
      if (p %in% colnames(sheets[[sheet]]) == FALSE) {
        next
      }
      
      sheets[[sheet]] <- sheets[[sheet]] %>%
        dplyr::mutate(!!p := as.character(!!rlang::sym(p))) 
    }
  }
  
}

## Process probe data
if("PROBE_DATA" %in% names(sheets) == TRUE){
  sheets[["PROBE_DATA"]] <- extract_date_time(sheets[["PROBE_DATA"]], "date_time")
  sheets[["PROBE_DATA"]]$time <- as.POSIXct(paste0("1899-12-31 ", sheets[["PROBE_DATA"]]$time_str))
}

merge <- dplyr::bind_rows(sheets) %>%
  dplyr::bind_rows(ea_wq_data)

### Standardise columns: order, adding missing (as NA)
merge <- restructure_wq_data(merge)

### Add date_time if missing 
merge <- merge %>%
  dplyr::mutate(date_time = ifelse(is.na(date_time), paste(as.character(date),
                                  substr(as.character(time), 12, nchar(as.character(time))),
                                  sep = " "), 
                                  date_time))

### Pivot long
param_names <- names(merge)[14:ncol(merge)]
merge <- merge %>%
  tidyr::pivot_longer(cols = all_of(param_names),
                      names_to = "parameter",
                      values_to = "result") %>%
  dplyr::filter(parameter %in% PARAMETERS)

### Match on metadata
full_data <- merge %>%
  dplyr::left_join(metadata, by = "location_name") %>%
  dplyr::left_join(standards) %>%
  dplyr::left_join(params)

### Calculate orthophosphate standards for charts

ortho_stds <- calc_orthop_stds(metadata, "location_name", "alkalinity", "altitude_m")

full_data <- full_data %>%
  dplyr::left_join(ortho_stds) %>%
  dplyr::mutate(HIGH = ifelse(parameter == "orthoP", orthoP_HIGH_mg, HIGH),
                GOOD = ifelse(parameter == "orthoP", orthoP_GOOD_mg, GOOD),
                MODERATE = ifelse(parameter == "orthoP", orthoP_MOD_mg, MODERATE),
                POOR = ifelse(parameter == "orthoP", orthoP_POOR_mg, POOR)) %>%
  dplyr::select(!starts_with("orthoP_"))

```

# Data Summary

```{r data_summary}

param_summ <- full_data %>%
  dplyr::group_by(location_name, parameter) %>%
  dplyr::summarise(n_samples = n()) %>%
  dplyr::ungroup() %>%
  tidyr::pivot_wider(names_from = parameter, values_from = n_samples)

# Update text
report_table <- full_data %>%
  dplyr::mutate(src = case_when(source == "EA_DATA" ~ "EA",
                                source == "MANUAL_FIELD" ~ "Field",
                                source == "LAB_DATA" ~ "Lab",
                                source == "PROBE_DATA" ~ "Probe"))

report_table <- report_table %>%
  dplyr::group_by(location_name) %>%
  dplyr::summarise(
    source = paste(unique(src), collapse = ", "),
    min_date = as.character(min(date, na.rm = TRUE)),
    max_date = as.character(max(date, na.rm = TRUE)),
    lat = round(mean(latitude, na.rm = TRUE), 5),
    lon = round(mean(longitude, na.rm = TRUE), 5),
    samples = n()
  ) %>%
  dplyr::ungroup()
  
report_table <- report_table %>%
  dplyr::left_join(param_summ, by = "location_name") %>%
  dplyr::mutate(location_name = factor(location_name, levels = APEM_SITES)) %>%
  dplyr::arrange(location_name)
  
### Restructure
report_table_t <- data.table::transpose(report_table, make.names = 1)
rownames(report_table_t) <- SUMM_ROW_NAMES[2:length(SUMM_ROW_NAMES)]

### Output table
report_table_output <- DT::datatable(report_table_t, extensions = "Buttons", 
                                     options = list(
                                       pageLength = nrow(report_table_t),
                                       dom = 'Brti',
                                       buttons = c('copy', 'csv', 'excel')))

```

The following table summarises the available data:

`r report_table_output`

# Quality Checks

## Limits of detection (LOD)

```{r process_lod}

### Process LOD results and export/tabulate
full_data <- full_data %>%
  dplyr::mutate(limit = ifelse(grepl("<", result) == TRUE | grepl(">", result) == TRUE,
                               substr(result,regexpr("[[:digit:]]", result), nchar(result)), NA_character_),
                limit = as.numeric(limit),
                original_result = result,
                result = as.numeric(result),
                result = ifelse(is.na(limit)==FALSE, limit * LOD_MULTIPLIER, result))

lod_tab_data <- full_data %>%
  dplyr::filter(is.na(limit) == FALSE) %>%
  dplyr::select(location_name, date, source, output_headers, limit)

colnames(lod_tab_data) <- c("Location", "Date", "Data source", "Parameter (units)", "LOD")

if (nrow(lod_tab_data) > 0) {
  LOD_tab <- DT::datatable(lod_tab_data)
} else {
  LOD_tab <- "NA - No results outwith LOD"
}

```

The table below summarises results that are outwith the limit of detection (LOD). For further processing, these results will be multiplied by the value specified by the user.

**`r LOD_tab`**

## Excluded Results

```{r qc_checks}

# Negative results/outside possible range
full_data <- full_data %>%
  dplyr::mutate(exclude = ifelse(result < 0 | result > 100, TRUE, FALSE))   # Add others as required

exclusions_data <- full_data %>%
  dplyr::filter(exclude) %>%
  dplyr::select(location_name, date, source, output_headers, result)

colnames(exclusions_data) <- c("Location", "Date", "Data source", "Parameter (units)", "Excluded result")

if (nrow(exclusions_data) > 0) {
  EXCL_tab <- DT::datatable(exclusions_data)
} else {
  EXCL_tab <- "NA - No excluded results"
}

full_data <- full_data %>%
  dplyr::filter(exclude == FALSE)

```

The following results have been excluded as being outside the allowed range for the appropriate parameters.

**`r EXCL_tab`**

## Potential Outliers

```{r process_outliers}

full_data <- full_data %>%
  dplyr::mutate(outlier = FALSE)

for (l in unique(full_data$location_name)){
  for (p in PARAMETERS) {
    temp <- full_data %>%
      dplyr::filter(parameter == p & location_name == l)

    t <- ggplot(temp) +
      aes(x = "", y = result) +
      geom_boxplot() +
      labs(title = p)

    outs <- boxplot.stats(temp$result)$out

    full_data <- full_data %>%
      dplyr::mutate(outlier = ifelse(location_name == l & parameter == p & result %in% outs,
                                     TRUE, outlier))
  }
}

outliers_data <- full_data %>%
  dplyr::filter(outlier) %>%
  dplyr::select(location_name, date, source, output_headers, result)

colnames(outliers_data) <- c("Location", "Date", "Data source", "Parameter (units)", "Result")

if (nrow(outliers_data) > 0) {
  OUT_tab <- DT::datatable(outliers_data)
} else {
  OUT_tab <- "NA - No potential outliers identified"
}

```

The table below summarises results that have been identified as potential outliers:

**`r OUT_tab`**

```{r process_stats}

### Calculate summary statistics from all data and tabulate
summary_1 <- full_data %>%
  dplyr::group_by(location_name, output_headers) %>%
  dplyr::summarise(mn = mean(result, na.rm = TRUE),
                   sd = sd(result, na.rm = TRUE),
                   min = min(result, na.rm = TRUE),
                   max = max(result, na.rm = TRUE),
                   percentile = case_when(any(parameter == "temp")    ~ 0.98,
                                          any(parameter == "RDO_sat") ~ 0.1,
                                          any(parameter == "pH")      ~ 0.05,
                                          any(parameter == "BOD")     ~ 0.9,
                                          any(parameter == "amm_N")   ~ 0.9,
                                          .default = NA_integer_),
                   percentile_value = case_when(any(parameter == "temp")    ~ mn + (TEMP_Z * sd),
                                                any(parameter == "RDO_sat") ~ mn + (DO_Z * sd),
                                                any(parameter == "pH")      ~ mn + (PH_Z * sd),
                                                any(parameter == "BOD")     ~ exp(log(mn/(sqrt(1+((sd**sd)/(mn*mn))))) + (BOD_Z * sqrt(log(1+((sd*sd)/(mn*mn)))))),
                                                any(parameter == "amm_N")   ~ exp(log(mn/(sqrt(1+((sd**sd)/(mn*mn))))) + (AMM_Z * sqrt(log(1+((sd*sd)/(mn*mn)))))),
                                                .default = NA_integer_),
                   n_samples = n()
                   ) %>%
  dplyr::ungroup()

summary_1_ph2 <- full_data %>%
  dplyr::filter(parameter == "pH") %>%
  dplyr::group_by(location_name, output_headers) %>%
  dplyr::summarise(mn = mean(result, na.rm = TRUE),
                   sd = sd(result, na.rm = TRUE),
                   min = NA_integer_,
                   max = NA_integer_,
                   percentile = 0.95,
                   percentile_value = mn + (1.645 * sd),
                   n_samples = n()
                   ) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(mn = NA_integer_,
                sd = NA_integer_)

if(nrow(summary_1_ph2) > 0){
  summary_tab_data <- rbind(summary_1, summary_1_ph2) %>%
    dplyr::arrange(location_name, output_headers)
}

### Format for reporting
summary_tab_data <- summary_tab_data %>%
  dplyr::mutate(across(c(mn, sd, min, max, percentile, percentile_value), ~ round(., digits = 2)))
colnames(summary_tab_data) <- c("Location", "Parameter", "Mean", "SD", "Min", "Max", "Percentile", "Percentile value", "No. samples")

### Interactive table for report
summary_tab <- DT::datatable(summary_tab_data, extensions = "Buttons", 
                                     options = list(
                                       pageLength = nrow(summary_1),
                                       dom = 'Bfrtip',
                                       buttons = c('copy', 'csv', 'excel')))

### Merge result back to main data
### format
summary_1_ph2 <- summary_1_ph2 %>%
  dplyr::select(location_name, output_headers, percentile, percentile_value) %>%
  dplyr::rename(percentile2 = percentile, percentile2_value = percentile_value)

summary_1 <- summary_1 %>%
  dplyr::left_join(summary_1_ph2)

full_data <- full_data %>%
  dplyr::left_join(summary_1)

```

# Summary results

The table below shows summary results for all sites across all data sources (lab, field and probe data). The first page shows the results for all data except the exclusions noted in section 3.2, while page 2 shows the results with the potential outliers shown in section 3.3 also excluded.

`r summary_tab`


```{r process_status}

# Identify order of parameters (HIGH > POOR or POOR > HIGH)
# Compare result to standards
full_data <- full_data %>%
  dplyr::mutate(std_order = case_when(HIGH > POOR ~ "desc",
                                      POOR > HIGH ~ "asc",
                                      parameter == "pH" ~ "pH",
                                      .default = "none"),
                status = case_when(std_order == "desc" ~   ifelse(result > HIGH, "High",
                                                          ifelse(result < HIGH & result >= GOOD, "Good",
                                                          ifelse(result < GOOD & result >= MODERATE, "Moderate",
                                                          ifelse(result < MODERATE & result >= POOR, "Poor",
                                                          ifelse(result < POOR, "Bad", "Unclassified"))))),
                                   std_order == "asc" ~  ifelse(result > POOR, "BAD",
                                                          ifelse(result < POOR & result >= MODERATE, "Poor",
                                                          ifelse(result < MODERATE & result >= GOOD, "Good",
                                                          ifelse(result < GOOD & result >= HIGH, "Good",
                                                          ifelse(result < HIGH, "HIGH", "Unclassified"))))),
                                   std_order == "pH" ~    ifelse(result > 6 & result < 9, "High", "Not high"),
                                   .default = NA_character_))

```

# Charts

## Site Location

```{r map}

### Get location data only.
map_data <- full_data %>%
  dplyr::group_by(location_name) %>%
  dplyr::summarise(lat = mean(latitude, na.rm = TRUE),
                   lon = mean(longitude, na.rm = TRUE)) %>%
  dplyr::ungroup()

# if (exists("ea_site_info") == TRUE) {
#   ea_map_data <- ea_site_info %>%
#     dplyr::group_by(EA_ID) %>%
#     dplyr::summarise(lat = mean(lat, na.rm = TRUE),
#                      lon = mean(long, na.rm = TRUE)) %>%
#     dplyr::ungroup() %>%
#     dplyr::rename(location_name = EA_ID)
#   
#   map_data <- map_data %>%
#     dplyr::rows_append(ea_map_data)
# }  

### Generate map
map <- leaflet() %>%
  fitBounds(min(map_data$lon), min(map_data$lat), max(map_data$lon), max(map_data$lat)) %>%
  addTiles() %>%
  addPopups(lng = map_data$lon, lat = map_data$lat, map_data$location_name,
            options = popupOptions(closeButton = FALSE))

```

`r map`

## Time series plots

``` {r ts_plots, out.width = "80%"}

### Add seasons
full_data <- calculate_season(full_data, "date")

### Add data labels
full_data <- full_data %>%
  dplyr::mutate(source_name = str_to_title(substr(source, 1, regexpr("_", source)-1)),
                source_name = ifelse(source_name == "Ea", "EA", source_name))

### Set up for loop
charts <- list()
counter <- 1

#Set number of breaks for x-axis
n_years <- max(lubridate::year(full_data$date)) - min(lubridate::year(full_data$date))
breaks <- if(n_years<=2) {"1 month"} else if(n_years <= 10) { "1 years"} else if(n_years >10 & n_years <= 20) { "2 years"} else {"5 years"} 

### Loop through site/parameter combinations and plot
for (p in unique(full_data$parameter)) {

  ## Set up chart data
  chart_data <- full_data %>%
    dplyr::filter(parameter == p) %>%
    dplyr::mutate(x_min = as.Date(paste0(as.character(lubridate::year(min(date))), "-01-01")),
                  x_max = as.Date(paste0(as.character(lubridate::year(max(date))), "-12-31")),
                  y_min = min(result, HIGH - 10, POOR, -10, na.rm = TRUE),
                  y_min = ifelse(y_min < 0, 0, y_min_val),
                  y_max = max(result, HIGH * 1.1, POOR * 1.1, na.rm = TRUE),
                  feature = factor(feature, levels = c("Upstream", "Downstream")))

  y_min_val <- ifelse(p =="pH", 0, min(chart_data$y_min))
  y_max_val <- ifelse(p == "pH", 15, max(chart_data$y_max))
  x_min_val <- unique(chart_data$x_min)
  x_max_val <- unique(chart_data$x_max)
  p_name <- unique(chart_data$output_headers)
  xbreak <- round(length(unique(chart_data$date)), digits = 0)

  ### Charts with high status to top (higher values, higher status)
  if (unique(chart_data$std_order) == "asc"){
    chart<-ggplot(data = chart_data) +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = y_min_val, ymax = HIGH, xmin = x_min_val, xmax = x_max_val, text = "High"), fill = '#B7DEE8', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = HIGH, ymax = GOOD, xmin = x_min_val, xmax = x_max_val, text = "Good"), fill = '#D8E4BC', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = GOOD, ymax = MODERATE, xmin = x_min_val, xmax = x_max_val, text = "Moderate"), fill = '#FFFF66', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = MODERATE, ymax = POOR, xmin = x_min_val, xmax = x_max_val, text = "Poor"), fill = '#FFCC66', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = POOR, ymax = y_max_val, xmin = x_min_val, xmax = x_max_val, text = "Bad"), fill = '#FF9999', alpha = 1)} +
      {if(CHART_TYPE == "line")geom_rect(data = subset(chart_data, main_trib == "tributary")[1,], aes(fill = "#D9D9D9", xmin = x_min_val, xmax = x_max_val, ymin = y_min_val, ymax = y_max_val),  alpha = 0.5)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = HIGH), colour = '#B7DEE8', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = GOOD), colour = '#D8E4BC', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = MODERATE), colour = '#FFFF66', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = POOR), colour = '#FFCC66', linetype = 2, linewidth = 1.2)} +
      {if(SHOW_DATA_SOURCE == TRUE)geom_point(aes(x = as.Date(date), y = result, shape = source_name), pch = 21, colour = "lightgrey", fill = "black", size = 3)} +
      {if(SHOW_DATA_SOURCE == FALSE)geom_point(aes(x = as.Date(date), y = result), pch = 21, colour = "lightgrey", fill = "black", size = 3)}
  }

  ### Charts with bad  status to top (higher values, lower status)
  if(unique(chart_data$std_order == "desc")){
    chart<-ggplot(data = chart_data) +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = y_min_val, ymax = POOR, xmin = x_min_val, xmax = x_max_val, text = "Bad"), fill = '#FF9999', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = POOR, ymax = MODERATE, xmin = x_min_val, xmax = x_max_val, text = "Poor"), fill = '#FFCC66', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = MODERATE, ymax = GOOD, xmin = x_min_val, xmax = x_max_val, text = "Moderate"), fill = '#FFFF66', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = GOOD, ymax = HIGH, xmin = x_min_val, xmax = x_max_val, text = "Good"), fill = '#D8E4BC', alpha = 1)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = HIGH, ymax = y_max_val, xmin = x_min_val, xmax = x_max_val, text = "High"), fill = '#B7DEE8', alpha = 1)} +
      {if(CHART_TYPE == "line")geom_rect(data = subset(chart_data, main_trib == "tributary")[1,], aes(fill = "#D9D9D9", xmin = x_min_val, xmax = x_max_val, ymin = y_min_val, ymax = y_max_val),  alpha = 0.5)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = POOR), colour = '#FFCC66', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = MODERATE), colour = '#FFFF66', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = GOOD), colour = '#D8E4BC', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = HIGH), colour = '#B7DEE8', linetype = 2, linewidth = 1.2)} +
      {if(SHOW_DATA_SOURCE == TRUE)geom_point(aes(x = as.Date(date), y = result, shape = source_name))} +
      {if(SHOW_DATA_SOURCE == FALSE)geom_point(aes(x = as.Date(date), y = result))}
  }

  ### pH specific chart: high status between 6 and 9
  if(unique(chart_data$std_order == "pH")){
    chart<-ggplot(data = chart_data) +
      {if(CHART_TYPE == "line")geom_rect(data = subset(chart_data, main_trib == "tributary")[1,], aes(fill = "#D9D9D9", xmin = x_min_val, xmax = x_max_val, ymin = 0, ymax = 15), alpha = 0.5)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = 6), colour = '#B7DEE8', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "line")geom_hline(aes(yintercept = 9), colour = '#B7DEE8', linetype = 2, linewidth = 1.2)} +
      {if(CHART_TYPE == "block")geom_rect(aes(ymin = 6, ymax = 9, xmin = x_min_val, xmax = x_max_val), fill = '#B7DEE8', alpha = 1)} +
      {if(SHOW_DATA_SOURCE == TRUE)geom_point(aes(x = as.Date(date), y = result, shape = source_name))} +
      {if(SHOW_DATA_SOURCE == FALSE)geom_point(aes(x = as.Date(date), y = result))} 
  }

  ### Parameters without WFD standards
  if(unique(chart_data$std_order == "none")){

    ## Add nitrate standard if nitrate plot and SHOW_NITRATE_STANDARD set
    nitrate <- FALSE
    if(p == "nitrate" & SHOW_NITRATE_STANDARD == TRUE) {

      nitrate <- TRUE
      y_max_val <- ifelse(p == "nitrate", max(max(chart_data$y_max), 11.5), max(chart_data$y_max))

    }

    chart<-ggplot(data = chart_data) +
      {if(CHART_TYPE == "line")geom_rect(data = subset(chart_data, main_trib == "tributary")[1,], aes(fill = "#D9D9D9", xmin = x_min_val, xmax = x_max_val, ymin = y_min_val, ymax = y_max_val),  alpha = 0.5)} +
      {if(nitrate) geom_hline(aes(yintercept = 11.3), colour = "black", linetype = 2, linewidth = 1.2)} +
      {if(SHOW_DATA_SOURCE == TRUE)geom_point(aes(x = as.Date(date), y = result, shape = source_name))} +
      {if(SHOW_DATA_SOURCE == FALSE)geom_point(aes(x = as.Date(date), y = result))} 
  }

  ## Apply chart formatting
    dformat <- ifelse(breaks == "1 year", "%b-%Y", "%Y")

    chart <- chart +
    # chart +
      scale_x_date(date_breaks = breaks, date_labels = dformat) +
      scale_y_continuous(limits = c(y_min_val, y_max_val), breaks = pretty_breaks()) +
      {if(CHART_TYPE == "line")scale_fill_manual(values="#D9D9D9", labels=c("Tributary river"), name = "")} +
      theme_bw() +
      theme(title = element_text(family = "Calibri", size = 11, face = "bold"),
            text = element_text(family = "Calibri", size = 11, face = "bold"),
            axis.text.x = element_text(angle = 45, vjust = 0.5),
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank()) +
      scale_shape_manual(values = c(3,4,1,5)) +
      labs(y = p_name,
           x = "",
           shape = "Data source",
           title = p_name)
    
    
    ## Apply faceting
    if(sum(is.na(chart_data$feature)) == 0) {
      chart <- chart + facet_nested(parameter~feature+location_name, switch = "y", scales = "free_y")
    } else {
      chart <- chart + facet_grid(parameter~location_name, switch = "y", scales = "free_y")
    }
    
    ggsave(plot = chart, filename = paste0("Output/facet_plot_",p,"_", as.character(Sys.Date()), ".png"),
           width = 30, height = 15, units = "cm")
    
    c <- plotly::ggplotly(chart, width = 800) %>%
      layout(autosize = FALSE, margin = list(l = 50, r = 50, b = 110, t = 110, pad = 4))
    c <- plotly_legends(c)
    charts[[counter]] <- c
    counter <- counter + 1
    
}

htmltools::tagList(charts)

```

```{r wide_table}

### Restructure full data for reporting.
wide_output <- full_data %>%
  dplyr::select(c(date_time, location_name, source, output_headers, original_result)) %>%
  tidyr::pivot_wider(names_from = output_headers, values_from = original_result)

### Restructure summary table for reporting.
wide_summary <- summary_tab_data %>%
  dplyr::filter(!(is.na(Mean) & Parameter == "pH")) %>%
  dplyr::left_join(summary_1_ph2, by = c("Location" = "location_name", "Parameter" = "output_headers")) %>%
  dplyr::rename("Percentile 2" = percentile2, "Percentile 2 value" = percentile2_value) %>%
  tidyr::pivot_longer(cols = c(Mean, SD, Min, Max, Percentile, "Percentile value", "Percentile 2", "Percentile 2 value", "No. samples"),
                      names_to = "metric",
                      values_to = "value") %>%
  tidyr::pivot_wider(names_from = Parameter, values_from = value) %>%
  dplyr::arrange(Location)

```

```{r final_summary}

col_names <- c("Location name", "Data period", "No. samples", "Temp (C, 98%ile)", "DO(%, 10%ile)", "pH(5%ile)", "pH(95%ile)", "Ammonia(mg/l, 90%ile)", "Orthophosphate(mg/l, mean)", "BOD(mg/l, 90%ile)")

params <- colnames(wide_summary)[3:ncol(wide_summary)]

summary_report <- wide_summary %>%
  dplyr::filter(metric %in% c("Mean", "Percentile value", "Percentile 2 value")) %>%
  dplyr::mutate(across(all_of(params[c(1:4, 6, 7)]),~ifelse(metric == "Mean", NA, .)))

## Separate out second pH percentile values
ph_95 <- summary_report %>%
  dplyr::filter(metric == "Percentile 2 value") %>%
  dplyr::select(Location, pH) %>%
  dplyr::rename(pH_95 = pH)

summary_report <- summary_report %>%
  dplyr::filter(metric != "Percentile 2 value") %>%
  dplyr::group_by(Location) %>%
  dplyr::summarise(across(all_of(params),~mean(., na.rm = TRUE))) %>%
  dplyr::ungroup()

## Get n_samples
samples <- summary_tab_data %>%
  dplyr::group_by(Location) %>%
  dplyr::summarise(n_samples = mean(`No. samples`, na.rm = TRUE)) %>%
  dplyr::ungroup()

summary_report <- summary_report %>%
  dplyr::left_join(samples) %>%
  dplyr::left_join(ph_95)

## Get time period for report
years <- full_data %>%
  dplyr::group_by(location_name) %>%
  dplyr::summarise(min_yr = min(lubridate::year(date_time), na.rm = TRUE),
                   max_yr = max(lubridate::year(date_time), na.rm = TRUE)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(period = paste0(as.character(min_yr), " - ", as.character(max_yr))) %>%
  dplyr::select(location_name, period)

summary_report <- summary_report %>%
  dplyr::left_join(years, by = c("Location" = "location_name")) %>%
  dplyr::select(Location, period, n_samples, "Temperature (Â°C)", "DO (%)", "pH", "pH_95", "Ammoniacal Nitrogen as N (mg/L)", "Orthophosphate as P (mg/L)", "Biochemical Oxygen Demand (mg/L)")

colnames(summary_report) <- col_names

```

```{r data_export}

### List of sheets to include in output
if (exists("ea_wq_data") == FALSE) {
  ea_wq_data <- NULL
}

wb <- openxlsx::buildWorkbook(list(sheets[["PROBE_DATA"]], sheets[["LAB_DATA"]], sheets[["MANUAL_FIELD"]], ea_wq_data, lod_tab_data, exclusions_data, outliers_data, summary_tab_data, full_data, wide_output, wide_summary, desc))

### Apply sheet names
names(wb) <- c("PROBE_DATA", "LAB_DATA", "MANUAL_FIELD", "EA_DATA", "OUTWITH_LOD", "EXCLUSIONS", "OUTLIERS", "SUMMARY", "FULL_DATA", "WIDE_FORMAT", "WIDE_FORMAT_SUMMARY", "DESCRIPTION")

### Conditional formatting
openxlsx::conditionalFormatting(wb, "FULL_DATA", cols = 17, rows = 0:nrow(full_data)+1,
                                rule = 'AND($AF1<>"", $AF1<>"limit")',
                                style = createStyle(fontColour = "#0070C0"))

openxlsx::conditionalFormatting(wb, "WIDE_FORMAT", cols = 4:ncol(wide_output), rows = 0:nrow(wide_output)+1,
                                rule = '=LEFT(D1, 1) = "<"',
                                style = createStyle(fontColour = "#0070C0"))

openxlsx::conditionalFormatting(wb, "WIDE_FORMAT", cols = 4:ncol(wide_output), rows = 0:nrow(wide_output)+1,
                                rule = '=LEFT(D1, 1) = ">"',
                                style = createStyle(fontColour = "#F79646"))

### Export
filename <- paste0("Output/WQ_analysis_data_", as.character(Sys.Date()), ".xlsx")

openxlsx::saveWorkbook(wb, file = filename, overwrite = TRUE)

```
